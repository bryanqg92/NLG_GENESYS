{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fis import *\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import pandas\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import tokenizer_from_json\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "class NLG_Genesys():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.fis = fis()\n",
    "        \n",
    "        with open('data/tokenizer.json', 'r', encoding='utf-8') as f:\n",
    "            tokenizer_json = f.read()\n",
    "            self.tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "\n",
    "    \n",
    "        self.Scaler = joblib.load('data\\scaler.joblib')\n",
    "        self.num_decoder_tokens = len(self.tokenizer.word_index) + 1\n",
    "\n",
    "        self.model = seq2seqLSTM(4, 64, self.num_decoder_tokens)\n",
    "        self.model.load_state_dict(torch.load('Modelos\\pytorch_lim_vocab\\seq2seqLSTM_model.pt'))\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self,input:list):\n",
    "        fuzzy_set=[]\n",
    "\n",
    "        # get Fuzzy set names \n",
    "        for i in range(len(input)):\n",
    "            if i == 0:\n",
    "                name,_= self.fis.get_membership(antecedent_name='proporcional',value=input[i])\n",
    "                fuzzy_set.append(name)\n",
    "            elif i == 1:\n",
    "                name,_= self.fis.get_membership(antecedent_name='derivativo',value=input[i])\n",
    "                fuzzy_set.append(name)\n",
    "            elif i == 2:\n",
    "                name,_= self.fis.get_membership(antecedent_name='salida',value=input[i])\n",
    "                fuzzy_set.append(name)\n",
    "            elif i == 3:\n",
    "                name,_= self.fis.get_membership(antecedent_name='salida',value=input[i])\n",
    "                fuzzy_set.append(name)\n",
    "\n",
    "        # Normalize and get tensor for decoder inputs        \n",
    "        enc_test_in = self.Scaler.transform(np.array(input).reshape(1,-1))   \n",
    "        enc_test_in = torch.tensor(enc_test_in.reshape(1,1,-1)).float()\n",
    "\n",
    "        #Tokenize fuzzy set names and padding\n",
    "        fuzzy_set=' '.join(fuzzy_set)\n",
    "        dec_test_in = self.tokenizer.texts_to_sequences([fuzzy_set])\n",
    "        dec_test_in = pad_sequences(dec_test_in, maxlen=self.num_decoder_tokens, padding='post', truncating='post')\n",
    "\n",
    "        # get decoder input tensor\n",
    "        dec_test_in = torch.tensor(dec_test_in).long()\n",
    "\n",
    "        self.model.eval()\n",
    "        # Hacer predicciones con el modelo cargado\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(enc_test_in, dec_test_in)\n",
    "            _, predicts = torch.max(preds.data, 1)\n",
    "\n",
    "        predicciones_finales = self.__predictions(predicts.numpy())\n",
    "        return predicciones_finales\n",
    "\n",
    "\n",
    "    def __predictions(self,preds):\n",
    "        preds_words = []\n",
    "        for i in range(preds.shape[0]):\n",
    "            preds_row = preds[i]\n",
    "            preds_row_words = []\n",
    "            for idx in preds_row:\n",
    "                if idx in self.tokenizer.index_word:\n",
    "                    preds_row_words.append(self.tokenizer.index_word[idx])\n",
    "            preds_words.append(' '.join(preds_row_words))\n",
    "\n",
    "        return ' '.join(preds_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seqLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_decoder_tokens, num_layers=1):\n",
    "        super(seq2seqLSTM, self).__init__()\n",
    "        self.encoder_lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.decoder_embedding = nn.Embedding(num_decoder_tokens, 128)\n",
    "        self.decoder_lstm = nn.LSTM(128, hidden_size, num_layers=1, batch_first=True)\n",
    "        self.linear_layer = nn.Linear(hidden_size, num_decoder_tokens)\n",
    "\n",
    "    def forward(self, inputs, dec_inputs):\n",
    "        enc_output, (state_h, state_c) = self.encoder_lstm(inputs)\n",
    "        embedding = self.decoder_embedding(dec_inputs)\n",
    "        decoder_output, _ = self.decoder_lstm(embedding, (state_h, state_c))\n",
    "        decoder_output = decoder_output.reshape(-1, decoder_output.shape[2])\n",
    "        linear_output = self.linear_layer(decoder_output)\n",
    "        # Remodela para que tenga el mismo n√∫mero de pasos de tiempo que dec_inputs\n",
    "        linear_output = linear_output.reshape(dec_inputs.shape[0], dec_inputs.shape[1], -1)\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = NLG_Genesys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "[-0.973660277,0.685095798,59.56100462,-9.122009236],\n",
    "[-0.377828726,0.568407083,46.67430895,12.77140921],\n",
    "[0.01567219,0.379727079,-13.13443793,61.17541422],\n",
    "[0.372804459,0.662840809,-84.56089181,87.96033443],\n",
    "[0.990658137,0.313651328,-30.9341863,-28.1316274],\n",
    "[-0.894200915,0.008267488,74.83362165,-24.45181324],\n",
    "[-0.468190925,0.019575402,61.08238042,-10.26384242],\n",
    "[0.019810769,0.000863419,23.91385244,32.84036038],\n",
    "[0.444760626,-0.00742206,-71.69119038,67.5243902],\n",
    "[0.975931682,-0.0353132,-30.37134636,-22.94441907],\n",
    "[-0.925427849,-0.574096066,88.75713081,-38.75713081],\n",
    "[-0.469932986,-0.261050124,81.16554977,-31.16554977],\n",
    "[-0.007347862,-0.425361015,60.36739308,-10.36739308],\n",
    "[0.373523294,-0.590534398,13.30958829,46.02849406],\n",
    "[0.902971201,-0.492407206,-23.53141338,-17.06282676],\n",
    "[-0.947488931,0.793020541,59.12481552,-8.249631049],\n",
    "[-0.331723123,0.63642343,39.75846852,18.53460957],\n",
    "[0.058486198,0.688639871,-21.69723966,64.38646487],\n",
    "[0.354756966,0.90586868,-80.95139323,86.60677246],\n",
    "[0.908604376,0.596051107,-39.13956237,-11.72087527],\n",
    "[-0.940906397,-0.031286348,79.66125599,-29.66125599],\n",
    "[-0.456236773,0.016182308,60.91704468,-10.22062591],\n",
    "[-0.073795792,0.02487639,32.44004927,25.08653337],\n",
    "[0.33504713,-0.02833159,-40.69294547,60.42721755],\n",
    "[0.923057508,0.02508882,-41.1428986,-6.689031356],\n",
    "[-0.976919282,-0.691433447,89.61532137,-39.61532137],\n",
    "[-0.42459674,-0.36844626,80.40994567,-30.40994567],\n",
    "[0.057579164,-0.773128795,52.80260447,-1.363125369],\n",
    "[0.346327935,-0.707799717,16.70900818,41.94919018],\n",
    "[0.896734243,-0.535691005,-23.11561621,-16.23123241],\n",
    "[-0.962375937,0.36487035,59.37293229,-8.745864575],\n",
    "[-0.347296585,0.490141157,42.0944878,16.58792684],\n",
    "[0.06574558,0.987705804,-23.14911591,64.93091847],\n",
    "[0.422075911,0.48106835,-87.79240891,85.58481781],\n",
    "[0.929792685,0.943977194,-37.02073154,-15.95853692],\n",
    "[-0.977643503,0.026914147,75.76141055,-25.41464388],\n",
    "[-0.350922908,-0.039946403,60.25201708,-9.266838318],\n",
    "[0.007901508,-0.008105208,28.69918332,29.77077815],\n",
    "[0.465417625,0.037736427,-72.59796276,61.85667046],\n",
    "[0.892911268,0.028127537,-43.5508124,-1.505378636],\n",
    "[-0.964863637,-0.669478224,89.41439394,-39.41439394],\n",
    "[-0.477627914,-0.280073077,81.29379857,-31.29379857],\n",
    "[-0.009788409,-0.541308062,60.48942047,-10.48942047],\n",
    "[0.460663168,-0.670877511,5.955788773,41.91157755],\n",
    "[0.926652127,-0.977768927,-25.11014183,-20.22028366],\n",
    "[-0.998165934,0.815672566,59.96943223,-9.938864454],\n",
    "[-0.461571175,0.262724904,51.02618625,7.947627498],\n",
    "[-0.0755047,0.240513311,1.32570504,50.56191247],\n",
    "[0.453065454,0.223814272,-84.69345456,79.38690911],\n",
    "[0.905463611,0.77398552,-39.4536389,-11.0927222],\n",
    "[-0.994422301,0.014832287,78.08752049,-27.99625566],\n",
    "[-0.462955959,0.005857598,61.70573688,-11.42906341],\n",
    "[-0.040867728,0.006244355,32.29719893,26.44728877],\n",
    "[0.4689018,-0.030901154,-59.35291792,55.68526387],\n",
    "[0.927234615,-0.022514308,-31.27407199,-11.760462],\n",
    "[-0.966609752,-0.637654896,89.44349586,-39.44349586],\n",
    "[-0.39021046,-0.625833275,79.51052301,-29.51052301],\n",
    "[0.035815084,-0.228802559,55.52311445,-4.627737338],\n",
    "[0.402667348,-0.270504183,9.822176806,49.64435361],\n",
    "[0.994986309,-0.897700303,-29.66575396,-29.33150792],\n",
    "[-0.955195763,0.294938855,59.25326272,-8.506525431],\n",
    "[-0.347003504,0.539915182,42.05052566,16.62456195],\n",
    "[-0.011246419,0.43601646,-8.313037114,58.5941976],\n",
    "[0.404427877,0.831800531,-89.55721226,89.11442453],\n",
    "[0.963801889,0.899157357,-33.61981112,-22.76037776],\n",
    "[-0.901902112,-0.013865397,77.7371003,-27.7371003],\n",
    "[-0.47739777,0.022524856,61.18643913,-10.26724376],\n",
    "[-0.062114991,0.0071577,33.67948762,24.53738359],\n",
    "[0.37782183,-0.035464172,-53.15646836,68.22387882],\n",
    "[0.907940958,0.035640476,-42.91450207,-2.99695021],\n",
    "[-0.943215246,-0.946856167,89.05358744,-39.05358744],\n",
    "[-0.488473636,-0.248855376,81.4745606,-31.4745606],\n",
    "[-0.062393613,-0.668639532,63.11968067,-13.11968067],\n",
    "[0.417029417,-0.276859738,8.864705558,47.72941112],\n",
    "[0.944565199,-0.65933207,-26.30434662,-22.60869324]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Modelos/pytorch_lim_vocab/results/resultados.txt', 'w') as f:\n",
    "    for i in range(len(inputs)):\n",
    "        resultado = modelo.predict(inputs[i])\n",
    "        f.write(resultado + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
