{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQgynOSEpSI9",
        "outputId": "37a095e3-c93a-45db-af6c-a6b3b97feb27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          P         D          L          R P_fuzzy_set  P_membership  \\\n",
            "0 -0.344708  0.267949  50.949905  24.525778       lejos      0.861770   \n",
            "1 -0.512704 -0.725829  90.972135 -53.639732       lejos      0.812159   \n",
            "2  0.388981 -0.031825 -49.601000  63.894966       cerca      0.972454   \n",
            "3 -0.918004 -0.325898  92.482375 -50.164266   muy lejos      0.863339   \n",
            "4  0.046981 -0.488745  51.090865  -2.041475          ok      0.882547   \n",
            "\n",
            "   D_fuzzy_set  D_membership                     L_fuzzy_set  L_membership  \\\n",
            "0  acercandose      1.000000      medio rápido hacia delante      0.905009   \n",
            "1   alejandose      1.000000        muy rápido hacia delante      1.000000   \n",
            "2   sin cambio      0.840877  más o menos rápido hacia atrás      0.759975   \n",
            "3   alejandose      1.000000        muy rápido hacia delante      1.000000   \n",
            "4   alejandose      1.000000      medio rápido hacia delante      0.890913   \n",
            "\n",
            "                      R_fuzzy_set  R_membership  \\\n",
            "0         despacito hacia delante      0.726289   \n",
            "1  más o menos rápido hacia atrás      0.659007   \n",
            "2       rápidamente hacia delante      0.805252   \n",
            "3  más o menos rápido hacia atrás      0.745893   \n",
            "4           muy lento hacia atrás      0.602074   \n",
            "\n",
            "                                                 CAT  \n",
            "0  Cuando estés lejos de la pared, pero te estás ...  \n",
            "1  Cuando estés lejos de la pared, y te estás ale...  \n",
            "2  Cuando estés cerca a la pared, pero ni te acer...  \n",
            "3  Cuando estés muy lejos de la pared, y te estás...  \n",
            "4  Cuando estés a la distancia requerida, pero te...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "  # Cargar el dataset\n",
        "data = pd.read_csv('FIS\\dataset.csv')\n",
        "\n",
        "  # Mostrar las primeras filas del dataset\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3ocdy5NVgrlC"
      },
      "outputs": [],
      "source": [
        "X = data[['P','D','L','R']].values\n",
        "y = data['CAT'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kpic9ASVgrlE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Ajusta las columnas numéricas con StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WswYTwlggrlG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(y)\n",
        "num_decoder_tokens = len(tokenizer.word_index) + 1\n",
        "y_tokenized = tokenizer.texts_to_sequences(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RTEQp3BugrlH"
      },
      "outputs": [],
      "source": [
        "max_len = max(len(s) for s in y_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_jxPUXh9rH4Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_tokenized, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dividir el conjunto de entrenamiento en conjunto de entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DIILcf0OgrlK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Ajustar la longitud de las secuencias de frases en y_train a max_len\n",
        "y_train = pad_sequences(y_train, maxlen=num_decoder_tokens, padding='post', truncating='post')\n",
        "\n",
        "# Ajustar la longitud de las secuencias de frases en y_val a max_len\n",
        "y_val = pad_sequences(y_val, maxlen=num_decoder_tokens, padding='post', truncating='post')\n",
        "\n",
        "# Ajustar la longitud de las secuencias de frases en y_test a max_len\n",
        "y_test = pad_sequences(y_test, maxlen=num_decoder_tokens, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBPQXyS2qttQ",
        "outputId": "debac058-e5a0-4500-9b2d-4b9bee1cc00b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tamaño X train (5999, 4)\n",
            "\n",
            "tamaño y train (5999, 41)\n",
            "\n",
            "tamaño X val (2000, 4)\n",
            "\n",
            "tamaño y val (2000, 41)\n",
            "\n",
            "tamaño X test (2000, 4)\n",
            "\n",
            "tamaño y test (2000, 41)\n"
          ]
        }
      ],
      "source": [
        "print('tamaño X train', X_train.shape)\n",
        "print('\\ntamaño y train', y_train.shape)\n",
        "print('\\ntamaño X val', X_val.shape)\n",
        "print('\\ntamaño y val', y_val.shape)\n",
        "print('\\ntamaño X test', X_test.shape)\n",
        "print('\\ntamaño y test', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JwRtZWu3grlO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "\n",
        "# Definir dimension de entrada para el encoder\n",
        "encoder_inputs = Input(shape=(1, 4))\n",
        "\n",
        "# Capa LSTM en el encoder\n",
        "encoder_lstm = LSTM(256, return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "# Se descartan las salidas del encoder y solo se toman los estados\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "O_yu_i2Usgz5"
      },
      "outputs": [],
      "source": [
        "# Definir dimension de entrada para el decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "# Capa de embedding en el decoder\n",
        "decoder_embedding = Embedding(num_decoder_tokens, output_dim=100)\n",
        "decoder_inputs_embedded = decoder_embedding(decoder_inputs)\n",
        "\n",
        "# Capa LSTM en el decoder, con los estados del encoder como inicialización\n",
        "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_embedded, initial_state=encoder_states)\n",
        "\n",
        "# Capa densa con activación softmax en el output\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Definir modelo encoder-decoder\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1EU2yBpuavja",
        "outputId": "27911daa-597e-4670-c98d-927c948c4950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "47/47 [==============================] - 19s 307ms/step - loss: 2.7771 - val_loss: 2.4274\n",
            "Epoch 2/15\n",
            "47/47 [==============================] - 13s 280ms/step - loss: 2.1234 - val_loss: 1.7266\n",
            "Epoch 3/15\n",
            "47/47 [==============================] - 13s 276ms/step - loss: 1.3718 - val_loss: 1.0745\n",
            "Epoch 4/15\n",
            "47/47 [==============================] - 13s 277ms/step - loss: 0.8733 - val_loss: 0.6861\n",
            "Epoch 5/15\n",
            "47/47 [==============================] - 13s 280ms/step - loss: 0.4824 - val_loss: 0.3068\n",
            "Epoch 6/15\n",
            "47/47 [==============================] - 13s 277ms/step - loss: 0.2093 - val_loss: 0.1448\n",
            "Epoch 7/15\n",
            "47/47 [==============================] - 13s 277ms/step - loss: 0.0793 - val_loss: 0.0434\n",
            "Epoch 8/15\n",
            "47/47 [==============================] - 14s 288ms/step - loss: 0.0257 - val_loss: 0.0156\n",
            "Epoch 9/15\n",
            "47/47 [==============================] - 14s 294ms/step - loss: 0.0110 - val_loss: 0.0080\n",
            "Epoch 10/15\n",
            "47/47 [==============================] - 14s 289ms/step - loss: 0.0064 - val_loss: 0.0052\n",
            "Epoch 11/15\n",
            "47/47 [==============================] - 14s 295ms/step - loss: 0.0044 - val_loss: 0.0038\n",
            "Epoch 12/15\n",
            "47/47 [==============================] - 13s 285ms/step - loss: 0.0033 - val_loss: 0.0029\n",
            "Epoch 13/15\n",
            "47/47 [==============================] - 13s 280ms/step - loss: 0.0027 - val_loss: 0.0024\n",
            "Epoch 14/15\n",
            "47/47 [==============================] - 13s 285ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 15/15\n",
            "47/47 [==============================] - 13s 284ms/step - loss: 0.0019 - val_loss: 0.0017\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x258f7cb25b0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Entrenar el modelo\n",
        "model.fit([X_train.reshape(5999,1,4), y_train], y_train.reshape(y_train.shape[0], y_train.shape[1], 1), batch_size=128, epochs=15, validation_data=([X_val.reshape(X_val.shape[0],1,4), y_val], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([11, 12, 16, 26,  8,  9, 17, 21, 23,  6, 31, 25, 23,  6, 32, 19, 18,\n",
              "        2,  3,  4, 13, 20,  5, 10,  7,  2,  3,  4, 14, 20,  5, 10,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate([X_test.reshape(X_test.shape[0],1,4),y_test[:,:-1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 5s 55ms/step\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict([X_test.reshape(X_test.shape[0], 1, 4), y_test[:,:-1]])\n",
        "\n",
        "# Convertir las predicciones de índices a palabras\n",
        "preds = np.argmax(preds, axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[11, 12, 16, ...,  0,  0,  0],\n",
              "       [11, 12,  8, ...,  0,  0,  0],\n",
              "       [11, 12,  8, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [11, 12, 28, ...,  0,  0,  0],\n",
              "       [11, 12, 16, ...,  0,  0,  0],\n",
              "       [11, 12, 16, ...,  0,  0,  0]], dtype=int64)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def predictions(preds):\n",
        "    preds_words = []\n",
        "    for i in range(preds.shape[0]):\n",
        "        preds_row = preds[i]\n",
        "        preds_row_words = []\n",
        "        for idx in preds_row:\n",
        "            if idx in tokenizer.index_word:\n",
        "                preds_row_words.append(tokenizer.index_word[idx])\n",
        "        preds_words.append(preds_row_words)\n",
        "\n",
        "    # Imprimir las primeras 10 predicciones\n",
        "    for i in range(10):\n",
        "        print(preds_words[i])\n",
        "\n",
        "    return preds_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cuando', 'estés', 'muy', 'cerca', 'a', 'la', 'pared', 'pero', 'ni', 'te', 'acercas', 'más', 'ni', 'te', 'alejas', 'de', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'despacito', 'hacia', 'atrás', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'atrás']\n",
            "['cuando', 'estés', 'a', 'la', 'distancia', 'requerida', 'y', 'ni', 'te', 'alejas', 'ni', 'te', 'acercas', 'a', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'despacito', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'delante']\n",
            "['cuando', 'estés', 'a', 'la', 'distancia', 'requerida', 'y', 'ni', 'te', 'alejas', 'ni', 'te', 'acercas', 'a', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'despacito', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'delante']\n",
            "['cuando', 'estés', 'cerca', 'a', 'la', 'pared', 'pero', 'ni', 'te', 'acercas', 'más', 'ni', 'te', 'alejas', 'de', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'bastante', 'rápido', 'hacia', 'atrás', 'y', 'gira', 'tu', 'rueda', 'derecha', 'bastante', 'rápido', 'hacia', 'delante']\n",
            "['cuando', 'estés', 'muy', 'lejos', 'de', 'la', 'pared', 'pero', 'te', 'estás', 'acercando', 'a', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'rápidamente', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'muy', 'lento', 'hacia', 'atrás']\n",
            "['cuando', 'estés', 'muy', 'lejos', 'de', 'la', 'pared', 'pero', 'te', 'estás', 'acercando', 'a', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'rápidamente', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'muy', 'lento', 'hacia', 'atrás']\n",
            "['cuando', 'estés', 'cerca', 'a', 'la', 'pared', 'pero', 'te', 'estás', 'alejando', 'de', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'muy', 'lento', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'medio', 'rápido', 'hacia', 'delante']\n",
            "['cuando', 'estés', 'lejos', 'de', 'la', 'pared', 'y', 'te', 'estás', 'alejando', 'más', 'de', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'bastante', 'rápido', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'atrás']\n",
            "['cuando', 'estés', 'muy', 'cerca', 'a', 'la', 'pared', 'pero', 'te', 'estás', 'alejando', 'de', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'despacito', 'hacia', 'atrás', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'atrás']\n",
            "['cuando', 'estés', 'a', 'la', 'distancia', 'requerida', 'y', 'ni', 'te', 'alejas', 'ni', 'te', 'acercas', 'a', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'despacito', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'delante']\n"
          ]
        }
      ],
      "source": [
        "frasesnlg = predictions(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_values = scaler.inverse_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  0.97207347,  -0.0330287 , -27.74293442, -12.93248209])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cuando', 'estés', 'muy', 'cerca', 'a', 'la', 'pared', 'pero', 'ni', 'te', 'acercas', 'más', 'ni', 'te', 'alejas', 'de', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'despacito', 'hacia', 'atrás', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'atrás']\n",
            "['cuando', 'estés', 'a', 'la', 'distancia', 'requerida', 'y', 'ni', 'te', 'alejas', 'ni', 'te', 'acercas', 'a', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'despacito', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'delante']\n",
            "['cuando', 'estés', 'a', 'la', 'distancia', 'requerida', 'y', 'ni', 'te', 'alejas', 'ni', 'te', 'acercas', 'a', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'despacito', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'delante']\n",
            "['cuando', 'estés', 'cerca', 'a', 'la', 'pared', 'pero', 'ni', 'te', 'acercas', 'más', 'ni', 'te', 'alejas', 'de', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'bastante', 'rápido', 'hacia', 'atrás', 'y', 'gira', 'tu', 'rueda', 'derecha', 'bastante', 'rápido', 'hacia', 'delante']\n",
            "['cuando', 'estés', 'muy', 'lejos', 'de', 'la', 'pared', 'pero', 'te', 'estás', 'acercando', 'a', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'rápidamente', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'muy', 'lento', 'hacia', 'atrás']\n",
            "['cuando', 'estés', 'muy', 'lejos', 'de', 'la', 'pared', 'pero', 'te', 'estás', 'acercando', 'a', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'rápidamente', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'muy', 'lento', 'hacia', 'atrás']\n",
            "['cuando', 'estés', 'cerca', 'a', 'la', 'pared', 'pero', 'te', 'estás', 'alejando', 'de', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'muy', 'lento', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'medio', 'rápido', 'hacia', 'delante']\n",
            "['cuando', 'estés', 'lejos', 'de', 'la', 'pared', 'y', 'te', 'estás', 'alejando', 'más', 'de', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'bastante', 'rápido', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'atrás']\n",
            "['cuando', 'estés', 'muy', 'cerca', 'a', 'la', 'pared', 'pero', 'te', 'estás', 'alejando', 'de', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'despacito', 'hacia', 'atrás', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'atrás']\n",
            "['cuando', 'estés', 'a', 'la', 'distancia', 'requerida', 'y', 'ni', 'te', 'alejas', 'ni', 'te', 'acercas', 'a', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'despacito', 'hacia', 'delante', 'y', 'gira', 'tu', 'rueda', 'derecha', 'despacito', 'hacia', 'delante']\n"
          ]
        }
      ],
      "source": [
        "preds_words = []\n",
        "for i in range(y_test.shape[0]):\n",
        "    preds_row = y_test[i]\n",
        "    preds_row_words = []\n",
        "    for idx in preds_row:\n",
        "        if idx in tokenizer.index_word:\n",
        "            preds_row_words.append(tokenizer.index_word[idx])\n",
        "    preds_words.append(preds_row_words)\n",
        "for i in range(10):\n",
        "    print(preds_words[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdlr = np.array([[-0.04182976,0.393413729,-3.725535952,54.77127996]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Cannot interpret '41' as a data type",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pdlrsalida \u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m,\u001b[39m41\u001b[39;49m)\n",
            "\u001b[1;31mTypeError\u001b[0m: Cannot interpret '41' as a data type"
          ]
        }
      ],
      "source": [
        "pdlrsalida =np.zeros(1,41)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 41)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        }
      ],
      "source": [
        "prueba = model.predict([pdlr.reshape(1,1,4),np.zeros((1,41))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "prueba = np.argmax(prueba, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'la']\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions(prueba)\n",
            "Cell \u001b[1;32mIn[18], line 13\u001b[0m, in \u001b[0;36mpredictions\u001b[1;34m(preds)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# Imprimir las primeras 10 predicciones\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mprint\u001b[39m(preds_words[i])\n\u001b[0;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m preds_words\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "predictions(prueba)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "deepLearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "2b41b25ee1e44cae6d514ffd9667bc76b20c566b16ce2b68cdb08e6b78e7fb09"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
