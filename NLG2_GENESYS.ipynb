{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQgynOSEpSI9",
        "outputId": "37a095e3-c93a-45db-af6c-a6b3b97feb27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          P         D          L          R P_fuzzy_set  P_membership  \\\n",
            "0  0.045553  0.608390 -18.517306  67.099168          ok      0.886118   \n",
            "1 -0.979829  0.468399  62.832204  -7.498536   muy lejos      0.966382   \n",
            "2  0.968055  0.035674 -34.584612 -12.701870   muy cerca      0.946758   \n",
            "3  0.402764  0.032081 -71.360223  77.859054       cerca      0.995394   \n",
            "4 -0.503925  0.629578  61.566158  16.442472       lejos      0.826791   \n",
            "\n",
            "   D_fuzzy_set  D_membership                  L_fuzzy_set  L_membership  \\\n",
            "0  acercandose      1.000000        muy lento hacia atrás      0.574135   \n",
            "1  acercandose      1.000000    rápidamente hacia delante      0.858390   \n",
            "2   sin cambio      0.821631        despacito hacia atrás      0.541539   \n",
            "3   sin cambio      0.839593  bastante rápido hacia atrás      0.784006   \n",
            "4  acercandose      1.000000    rápidamente hacia delante      0.921692   \n",
            "\n",
            "                     R_fuzzy_set  R_membership  \\\n",
            "0      rápidamente hacia delante      0.645042   \n",
            "1          muy lento hacia atrás      0.874927   \n",
            "2          muy lento hacia atrás      0.864907   \n",
            "3  bastante rápido hacia delante      0.892953   \n",
            "4        muy lento hacia delante      0.677876   \n",
            "\n",
            "                                               FRASE  CAT  \n",
            "0  en caso de que te estés acercando mientras est...    3  \n",
            "1  En caso de estar muy lejos de la pared y estás...    1  \n",
            "2  Cuando te encuentres muy cerca a la pared sin ...   10  \n",
            "3  Cuando estés cerca a la pared, pero ni te acer...    9  \n",
            "4  en caso de que te estes acercando al pared per...    2  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "  # Cargar el dataset\n",
        "data = pd.read_csv('data\\dataset_wide.csv')\n",
        "\n",
        "  # Mostrar las primeras filas del dataset\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#columnas a discretizar\n",
        "columns_discret = ['P',\n",
        " 'D',\n",
        " 'L',\n",
        " 'R',\n",
        " 'P_membership',\n",
        " 'D_membership',\n",
        " 'L_membership',\n",
        " 'R_membership'\n",
        " ]\n",
        "\n",
        "data_discretized = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in columns_discret:\n",
        "    data_discretized[col+'_discretized'] = pd.cut(data[col], 256, labels=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WswYTwlggrlG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(y)\n",
        "num_decoder_tokens = len(tokenizer.word_index) + 1\n",
        "y_tokenized = tokenizer.texts_to_sequences(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTEQp3BugrlH"
      },
      "outputs": [],
      "source": [
        "max_len = max(len(s) for s in y_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jxPUXh9rH4Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_tokenized, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dividir el conjunto de entrenamiento en conjunto de entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIILcf0OgrlK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Ajustar la longitud de las secuencias de frases en y_train a max_len\n",
        "y_train = pad_sequences(y_train, maxlen=num_decoder_tokens, padding='post', truncating='post')\n",
        "\n",
        "# Ajustar la longitud de las secuencias de frases en y_val a max_len\n",
        "y_val = pad_sequences(y_val, maxlen=num_decoder_tokens, padding='post', truncating='post')\n",
        "\n",
        "# Ajustar la longitud de las secuencias de frases en y_test a max_len\n",
        "y_test = pad_sequences(y_test, maxlen=num_decoder_tokens, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBPQXyS2qttQ",
        "outputId": "debac058-e5a0-4500-9b2d-4b9bee1cc00b"
      },
      "outputs": [],
      "source": [
        "print('tamaño X train', X_train.shape)\n",
        "print('\\ntamaño y train', y_train.shape)\n",
        "print('\\ntamaño X val', X_val.shape)\n",
        "print('\\ntamaño y val', y_val.shape)\n",
        "print('\\ntamaño X test', X_test.shape)\n",
        "print('\\ntamaño y test', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwRtZWu3grlO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "\n",
        "# Definir dimension de entrada para el encoder\n",
        "encoder_inputs = Input(shape=(1, 4))\n",
        "\n",
        "# Capa LSTM en el encoder\n",
        "encoder_lstm = LSTM(256, return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "# Se descartan las salidas del encoder y solo se toman los estados\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_yu_i2Usgz5"
      },
      "outputs": [],
      "source": [
        "# Definir dimension de entrada para el decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "# Capa de embedding en el decoder\n",
        "decoder_embedding = Embedding(num_decoder_tokens, output_dim=100)\n",
        "decoder_inputs_embedded = decoder_embedding(decoder_inputs)\n",
        "\n",
        "# Capa LSTM en el decoder, con los estados del encoder como inicialización\n",
        "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_embedded, initial_state=encoder_states)\n",
        "\n",
        "# Capa densa con activación softmax en el output\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Definir modelo encoder-decoder\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1EU2yBpuavja",
        "outputId": "27911daa-597e-4670-c98d-927c948c4950"
      },
      "outputs": [],
      "source": [
        "# Entrenar el modelo\n",
        "model.fit([X_train.reshape(5999,1,4), y_train], y_train.reshape(y_train.shape[0], y_train.shape[1], 1), batch_size=128, epochs=15, validation_data=([X_val.reshape(X_val.shape[0],1,4), y_val], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.evaluate([X_test.reshape(X_test.shape[0],1,4),y_test[:,:-1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = model.predict([X_test.reshape(X_test.shape[0], 1, 4), y_test[:,:-1]])\n",
        "\n",
        "# Convertir las predicciones de índices a palabras\n",
        "preds = np.argmax(preds, axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def predictions(preds):\n",
        "    preds_words = []\n",
        "    for i in range(preds.shape[0]):\n",
        "        preds_row = preds[i]\n",
        "        preds_row_words = []\n",
        "        for idx in preds_row:\n",
        "            if idx in tokenizer.index_word:\n",
        "                preds_row_words.append(tokenizer.index_word[idx])\n",
        "        preds_words.append(preds_row_words)\n",
        "\n",
        "    # Imprimir las primeras 10 predicciones\n",
        "    for i in range(10):\n",
        "        print(preds_words[i])\n",
        "\n",
        "    return preds_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frasesnlg = predictions(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_values = scaler.inverse_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds_words = []\n",
        "for i in range(y_test.shape[0]):\n",
        "    preds_row = y_test[i]\n",
        "    preds_row_words = []\n",
        "    for idx in preds_row:\n",
        "        if idx in tokenizer.index_word:\n",
        "            preds_row_words.append(tokenizer.index_word[idx])\n",
        "    preds_words.append(preds_row_words)\n",
        "for i in range(10):\n",
        "    print(preds_words[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdlr = np.array([[-0.04182976,0.393413729,-3.725535952,54.77127996]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdlrsalida =np.zeros(1,41)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prueba = model.predict([pdlr.reshape(1,1,4),np.zeros((1,41))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prueba = np.argmax(prueba, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions(prueba)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "deepLearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "2b41b25ee1e44cae6d514ffd9667bc76b20c566b16ce2b68cdb08e6b78e7fb09"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
