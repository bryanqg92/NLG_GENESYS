{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1913,"status":"ok","timestamp":1674397272532,"user":{"displayName":"Leandro Quiroga","userId":"14091389659952361655"},"user_tz":300},"id":"AQgynOSEpSI9","outputId":"dc1d2db3-2934-4a39-a1b3-1cee13c1cc77"},"outputs":[{"name":"stdout","output_type":"stream","text":["          P         D          L          R P_fuzzy_set  P_membership  \\\n","0 -0.000480  0.526110  -9.743533  63.120691          ok      0.998800   \n","1  0.944574  0.025943 -38.727943  -5.020554   muy cerca      0.907624   \n","2  0.023568  0.013238  12.355830  36.212792          ok      0.941080   \n","3 -0.982377  0.996781  62.889400  -7.795086   muy lejos      0.970628   \n","4  0.382476 -0.454730  13.321278  40.839750       cerca      0.956189   \n","\n","   D_fuzzy_set  D_membership                     L_fuzzy_set  L_membership  \\\n","0  acercandose      1.000000           muy lento hacia atrás      0.987177   \n","1   sin cambio      0.870285  más o menos rápido hacia atrás      0.872794   \n","2   sin cambio      0.933810         muy lento hacia delante      0.882208   \n","3  acercandose      1.000000       rápidamente hacia delante      0.855530   \n","4   alejandose      1.000000         muy lento hacia delante      0.833936   \n","\n","                  R_fuzzy_set  R_membership  \\\n","0   rápidamente hacia delante      0.843965   \n","1       muy lento hacia atrás      0.751028   \n","2     despacito hacia delante      0.689360   \n","3       muy lento hacia atrás      0.889754   \n","4  medio rápido hacia delante      0.541988   \n","\n","                                                 CAT  \n","0  en caso de que te estés acercando mientras est...  \n","1  Cuando estés muy cerca a la pared, pero ni te ...  \n","2  cuando estén a la distancia que es, y ni te ac...  \n","3  Cuando estés muy lejos de la pared, pero te es...  \n","4  Cuando estés cerca a la pared, pero te estás a...  \n"]}],"source":["import pandas as pd\n","import tensorflow as tf\n","import numpy as np\n","\n","  # Cargar el dataset\n","data = pd.read_csv('FIS\\dataset_wide.csv')\n","\n","  # Mostrar las primeras filas del dataset\n","print(data.head())"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["X = data[['P','D','L','R',]]\n","y = data['CAT']\n","z = data[['P_fuzzy_set', 'D_fuzzy_set', 'L_fuzzy_set', 'R_fuzzy_set']].apply(lambda x: ' '.join(x), axis=1)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["with open('FIS\\corpus.txt', 'r', encoding='utf-8') as f:\n","    contenido = f.read()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([contenido])\n","num_decoder_tokens = len(tokenizer.word_index) + 1\n","y_tokenized = tokenizer.texts_to_sequences(y)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":368,"status":"ok","timestamp":1674397277058,"user":{"displayName":"Leandro Quiroga","userId":"14091389659952361655"},"user_tz":300},"id":"_jxPUXh9rH4Q"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Dividir los datos en conjunto de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y_tokenized, test_size=0.2, random_state=42)\n","\n","# Dividir el conjunto de entrenamiento en conjunto de entrenamiento y validación\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n","\n","# Obtener el índice de las filas de X_train, X_val y X_test\n","idx_train = X_train.index\n","idx_val = X_val.index\n","idx_test = X_test.index"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Dividir z en z_train, z_val y z_test\n","z_train = z.loc[idx_train].values\n","z_val = z.loc[idx_val].values\n","z_test = z.loc[idx_test].values"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["z_train = tokenizer.texts_to_sequences(z_train)\n","z_val = tokenizer.texts_to_sequences(z_val)\n","z_test = tokenizer.texts_to_sequences(z_test)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["X_train = X_train[['P','D','L','R']].values\n","X_val = X_val[['P','D','L','R']].values\n","X_test = X_test[['P','D','L','R']].values"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"],"text/plain":["StandardScaler()"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import StandardScaler\n","\n","# Ajusta las columnas numéricas con StandardScaler\n","scaler_values = StandardScaler()\n","\n","scaler_values.fit(X_train)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["X_train_scaled = scaler_values.transform(X_train)\n","X_val_scaled =scaler_values.transform(X_val)\n","X_test_scaled =scaler_values.transform(X_test)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["max_len = max(len(s) for s in y_tokenized)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","y_train = pad_sequences(y_train, maxlen=num_decoder_tokens, padding='post', truncating='post')\n","y_val = pad_sequences(y_val, maxlen=num_decoder_tokens, padding='post', truncating='post')\n","y_test = pad_sequences(y_test, maxlen=num_decoder_tokens, padding='post', truncating='post')\n","z_train = pad_sequences(z_train, maxlen=num_decoder_tokens, padding='post', truncating='post')\n","z_val = pad_sequences(z_val, maxlen=num_decoder_tokens, padding='post', truncating='post')\n","z_test = pad_sequences(z_test, maxlen=num_decoder_tokens, padding='post', truncating='post')"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1674397281586,"user":{"displayName":"Leandro Quiroga","userId":"14091389659952361655"},"user_tz":300},"id":"WBPQXyS2qttQ","outputId":"efa41b8f-4c41-4d89-82e3-d678a39c0529"},"outputs":[{"name":"stdout","output_type":"stream","text":["tamaño X train_scaled (5999, 4)\n","tamaño y train (5999, 95)\n","tamaño z train (5999, 95)\n","tamaño X val_scaled (2000, 4)\n","tamaño y val (2000, 95)\n","tamaño z val_scaled (2000, 95)\n","tamaño X test_scaled (2000, 4)\n","tamaño y test (2000, 95)\n","tamaño z test (2000, 95)\n"]}],"source":["print('tamaño X train_scaled', X_train_scaled.shape)\n","print('tamaño y train', y_train.shape)\n","print('tamaño z train', z_train.shape)\n","\n","\n","print('tamaño X val_scaled', X_val_scaled.shape)\n","print('tamaño y val', y_val.shape)\n","print('tamaño z val_scaled', z_val.shape)\n","\n","print('tamaño X test_scaled', X_test_scaled.shape)\n","print('tamaño y test', y_test.shape)\n","print('tamaño z test', z_test.shape)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n","\n","# Definir dimension de entrada para el encoder\n","encoder_inputs = Input(shape=(1, 4))\n","\n","# Capa LSTM en el encoder\n","encoder_lstm = LSTM(128, return_state=True)\n","_, state_h, state_c = encoder_lstm(encoder_inputs)\n","\n","# Se descartan las salidas del encoder y solo se toman los estados\n","encoder_states = [state_h, state_c]"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# Definir dimension de entrada para el decoder\n","decoder_inputs = Input(shape=(None,))\n","\n","# Capa de embedding en el decoder\n","decoder_embedding = Embedding(num_decoder_tokens, output_dim=100)\n","decoder_inputs_embedded = decoder_embedding(decoder_inputs)\n","\n","# Capa LSTM en el decoder, con los estados del encoder como inicialización\n","decoder_lstm = LSTM(128, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs_embedded, initial_state=encoder_states)\n","\n","# Capa densa con activación softmax en el output\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Definir modelo encoder-decoder\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# Compilar el modelo\n","model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","200/200 [==============================] - 48s 241ms/step - loss: 0.8324 - val_loss: 0.8215\n","Epoch 2/15\n","200/200 [==============================] - 47s 236ms/step - loss: 0.7835 - val_loss: 0.7679\n","Epoch 3/15\n","200/200 [==============================] - 48s 241ms/step - loss: 0.7316 - val_loss: 0.6954\n","Epoch 4/15\n","200/200 [==============================] - 49s 247ms/step - loss: 0.6854 - val_loss: 0.6946\n","Epoch 5/15\n","200/200 [==============================] - 47s 236ms/step - loss: 0.6488 - val_loss: 0.6116\n","Epoch 6/15\n","200/200 [==============================] - 46s 231ms/step - loss: 0.6167 - val_loss: 0.6002\n","Epoch 7/15\n","200/200 [==============================] - 46s 229ms/step - loss: 0.5869 - val_loss: 0.6238\n","Epoch 8/15\n","200/200 [==============================] - 46s 232ms/step - loss: 0.5597 - val_loss: 0.5479\n","Epoch 9/15\n","169/200 [========================>.....] - ETA: 6s - loss: 0.5392"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit([X_train_scaled\u001b[39m.\u001b[39;49mreshape(\u001b[39m5999\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m4\u001b[39;49m), z_train], \n\u001b[0;32m      3\u001b[0m     y_train\u001b[39m.\u001b[39;49mreshape(y_train\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], y_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m),\n\u001b[0;32m      4\u001b[0m      batch_size\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, \n\u001b[0;32m      5\u001b[0m      epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m, \n\u001b[0;32m      6\u001b[0m      validation_data\u001b[39m=\u001b[39;49m([X_val_scaled\u001b[39m.\u001b[39;49mreshape(X_val\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m],\u001b[39m1\u001b[39;49m,\u001b[39m4\u001b[39;49m), z_val], y_val\u001b[39m.\u001b[39;49mreshape(y_val\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], y_val\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m)))\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Entrenar el modelo\n","model.fit([X_train_scaled.reshape(5999,1,4), z_train], \n","    y_train.reshape(y_train.shape[0], y_train.shape[1], 1),\n","     batch_size=30, \n","     epochs=15, \n","     validation_data=([X_val_scaled.reshape(X_val.shape[0],1,4), z_val], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["63/63 [==============================] - 1s 3ms/step - loss: 0.0000e+00\n"]},{"data":{"text/plain":["0.0"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate([X_test.reshape(X_test.shape[0],1,4),z_test])"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def predictions(preds):\n","    preds_words = []\n","    for i in range(preds.shape[0]):\n","        preds_row = preds[i]\n","        preds_row_words = []\n","        for idx in preds_row:\n","            if idx in tokenizer.index_word:\n","                preds_row_words.append(tokenizer.index_word[idx])\n","        preds_words.append(preds_row_words)\n","\n","    return preds_words"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["inPrueba = np.array([[-0.997111302,0.430978894,59.95185503,-9.90371007]])\n","inPrueba = scaler_values.transform(inPrueba).reshape(1,1,4)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["z_prueba = ['muy lejos acercandose muy rapidamente hacia delante muy lento hacia atrás']\n","z_prueba = tokenizer.texts_to_sequences(z_prueba)\n","z_prueba = pad_sequences(z_prueba, maxlen=max_len, padding='post', truncating='post')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["array([[[-1.52516433,  0.84932278,  0.76718668, -0.47877844]]])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["inPrueba"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 9, 24,  9,  3, 22,  9, 29,  3, 12,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0]])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["z_prueba"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 1s/step\n"]}],"source":["preds = model.predict([inPrueba, np.array(z_prueba)])\n","preds = np.argmax(preds, axis=-1)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[['cuando', 'caso', 'muy', 'lejos', 'de', 'la', 'pared', 'pero', 'te', 'estás', 'estás', 'a', 'ella', 'gira', 'tu', 'rueda', 'izquierda', 'hacia', 'delante', 'delante', 'y', 'la', 'rueda', 'derecha', 'derecha', 'lento', 'atrás', 'atrás']]\n"]}],"source":["frasesnlg = predictions(preds)\n","print(frasesnlg)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOVRQKgDkqK1BZfCmxZ07wH","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"deepLearning","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"2b41b25ee1e44cae6d514ffd9667bc76b20c566b16ce2b68cdb08e6b78e7fb09"}}},"nbformat":4,"nbformat_minor":0}
